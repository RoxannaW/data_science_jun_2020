{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595574066839",
   "display_name": "Python 3.6.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. From HTML\n",
    "\n",
    "*Using only beautiful soap*\n",
    "\n",
    "Save in a dataframe the next information using web scraping. Each row of the dataframe must have in different columns:\n",
    "\n",
    "- The name of the title\n",
    "- The id of the div where is the value scraped. If there is not id, then the value is must be numpy.nan\n",
    "- The name of the tag where is the value scraped.\n",
    "- The next scraped values in different rows: \n",
    "    - The value: \"Este es el segundo párrafo\"  --> Row 1\n",
    "    - The url https://pagina1.xyz/ --> Row 2\n",
    "    - The url https://pagina4.xyz/ --> Row 3\n",
    "    - The url https://pagina5.xyz/ --> Row 4\n",
    "    - The value \"links footer-links\" --> Row 5\n",
    "    - The value \"Este párrafo está en el footer\" --> Row 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"<html lang=\"es\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>Página de prueba</title>\n",
    "</head>\n",
    "<body>\n",
    "<div id=\"main\" class=\"full-width\">\n",
    "    <h1>El título de la página</h1>\n",
    "    <p>Este es el primer párrafo</p>\n",
    "    <p>Este es el segundo párrafo</p>\n",
    "    <div id=\"innerDiv\">\n",
    "        <div class=\"links\">\n",
    "            <a href=\"https://pagina1.xyz/\">Enlace 1</a>\n",
    "            <a href=\"https://pagina2.xyz/\">Enlace 2</a>\n",
    "        </div>\n",
    "        <div class=\"right\">\n",
    "            <div class=\"links\">\n",
    "                <a href=\"https://pagina3.xyz/\">Enlace 3</a>\n",
    "                <a href=\"https://pagina4.xyz/\">Enlace 4</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "    <div id=\"footer\">\n",
    "        <!-- El footer -->\n",
    "        <p>Este párrafo está en el footer</p>\n",
    "        <div class=\"links footer-links\">\n",
    "            <a href=\"https://pagina5.xyz/\">Enlace 5</a>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "</body>\n",
    "</html>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"index.html\", \"w\") as f:\n",
    "    f.write(html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists to use in dataframe\n",
    "title = []\n",
    "id_div = []\n",
    "tag_name = []\n",
    "value = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "title ['Página de prueba']\nid ['main']\ntag ['p']\nvalue ['Este es el primer párrafo']\n"
    }
   ],
   "source": [
    "#1#finding title and adding to list to use in df.\n",
    "title_content = soup.find('title')\n",
    "title_content_str = title_content.string\n",
    "title.append(title_content_str)\n",
    "print(\"title\", title)\n",
    "\n",
    "#1# getting the id name: Main and adding to list\n",
    "result = []\n",
    "for tag in soup.findAll(True,{'id':True}) :\n",
    "    result.append(tag['id'])\n",
    "\n",
    "id_div.append(result[0])\n",
    "print(\"id\", id_div)\n",
    "\n",
    "#1# find the tag: p and select the name of the tag and adding to list for df\n",
    "soup.find(\"p\").name\n",
    "tag_name.append(soup.find(\"p\").name)\n",
    "\n",
    "print(\"tag\", tag_name)\n",
    "\n",
    "#1# find the content in tag p and adding to list for df\n",
    "soup.find(\"p\").contents\n",
    "value.append(soup.find(\"p\").contents[0])\n",
    "print(\"value\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Página de prueba', 'Página de prueba']\n['main', nan]\n['p', 'a']\n['Este es el primer párrafo', 'https://pagina1.xyz/']\n"
    }
   ],
   "source": [
    "#2#finding title and adding to list to use in df.\n",
    "title_content = soup.find('title')\n",
    "title_content_str = title_content.string\n",
    "title.append(title_content_str)\n",
    "print(title)\n",
    "\n",
    "#2# checked where https://pagina1.xyz/ is stored and no id so added none to list for\n",
    "result = soup.find(\"div\", {\"class\":\"links\"})\n",
    "id_div.append(np.nan)\n",
    "print(id_div)\n",
    "\n",
    "#2# find tag name and added to list for df\n",
    "soup.find('a').name\n",
    "tag_name.append(soup.find('a').name)\n",
    "print(tag_name)\n",
    "\n",
    "#2# find content of link and added to value list for df\n",
    "link1 = soup.find(\"a\")\n",
    "content = link1.get('href')\n",
    "value.append(content)\n",
    "print(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Página de prueba', 'Página de prueba', 'Página de prueba']\n['main', nan, nan]\n['p', 'a', 'a']\n['Este es el primer párrafo', 'https://pagina1.xyz/', 'https://pagina4.xyz/']\n"
    }
   ],
   "source": [
    "#3# title added to lsit\n",
    "title_content = soup.find('title')\n",
    "title_content_str = title_content.string\n",
    "title.append(title_content_str)\n",
    "print(title)\n",
    "\n",
    "#3# no id in div, added none to list for df\n",
    "result = soup.find(\"div\", {\"class\":\"links\"})\n",
    "id_div.append(np.nan)\n",
    "print(id_div)\n",
    "\n",
    "#3# find tag name a and added to list\n",
    "soup.find('a').name\n",
    "tag_name.append(soup.find('a').name)\n",
    "print(tag_name)\n",
    "\n",
    "#3# finding the link and adding to value\n",
    "links = soup.findAll(\"a\")\n",
    "for pos, link in enumerate(links):\n",
    "    if pos == 3:\n",
    "        href = link.get('href')\n",
    "        value.append(href)\n",
    "\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Página de prueba', 'Página de prueba', 'Página de prueba', 'Página de prueba']\n['main', nan, nan, nan]\n['p', 'a', 'a', 'a']\n['Este es el primer párrafo', 'https://pagina1.xyz/', 'https://pagina4.xyz/', 'https://pagina5.xyz/']\n"
    }
   ],
   "source": [
    "#4# title added to lsit\n",
    "title_content = soup.find('title')\n",
    "title_content_str = title_content.string\n",
    "title.append(title_content_str)\n",
    "print(title)\n",
    "\n",
    "#4# no id in div, added none to list for df\n",
    "result = soup.find(\"div\", {\"class\":\"links\"})\n",
    "id_div.append(np.nan)\n",
    "print(id_div)\n",
    "\n",
    "#4# find tag name a and added to list\n",
    "soup.find('a').name\n",
    "tag_name.append(soup.find('a').name)\n",
    "print(tag_name)\n",
    "\n",
    "#4# finding the link and adding to value\n",
    "links = soup.findAll(\"a\")\n",
    "for pos, link in enumerate(links):\n",
    "    if pos == 4:\n",
    "        href = link.get('href')\n",
    "        value.append(href)\n",
    "\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Página de prueba', 'Página de prueba', 'Página de prueba', 'Página de prueba', 'Página de prueba']\n['main', nan, nan, nan, 'footer']\n['p', 'a', 'a', 'a', 'div']\n['Este es el primer párrafo', 'https://pagina1.xyz/', 'https://pagina4.xyz/', 'https://pagina5.xyz/', 'links footer-links']\n"
    }
   ],
   "source": [
    "#5# title added to lsit\n",
    "title_content = soup.find('title')\n",
    "title_content_str = title_content.string\n",
    "title.append(title_content_str)\n",
    "print(title)\n",
    "\n",
    "#5# id of div is footer. finding id name and adding to list. \n",
    "result = []\n",
    "for tag in soup.findAll(True,{'id':True}) :\n",
    "    result.append(tag['id'])\n",
    "\n",
    "id_div.append(result[2])\n",
    "print(id_div)\n",
    "\n",
    "#5# find tag name: div a and added to list\n",
    "soup.find(\"div\").name\n",
    "tag_name.append(soup.find(\"div\").name)\n",
    "print(tag_name)\n",
    "\n",
    "#5# finding the value links footer-links and adding to value\n",
    "all_div =  soup.find(\"div\", id=\"footer\")\n",
    "all_div_1 = all_div.find(\"div\")\n",
    "result = all_div_1.get_attribute_list('class')\n",
    "final_result = [str(result[0])+ \" \" + str(result[1])]\n",
    "value.append(final_result[0])\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Página de prueba', 'Página de prueba', 'Página de prueba', 'Página de prueba', 'Página de prueba', 'Página de prueba']\n['main', nan, nan, nan, 'footer', 'footer']\n['p', 'a', 'a', 'a', 'div', 'p']\n['Este es el primer párrafo', 'https://pagina1.xyz/', 'https://pagina4.xyz/', 'https://pagina5.xyz/', 'links footer-links', 'Este párrafo está en el footer']\n"
    }
   ],
   "source": [
    "#6# title added to lsit\n",
    "title_content = soup.find('title')\n",
    "title_content_str = title_content.string\n",
    "title.append(title_content_str)\n",
    "print(title)\n",
    "\n",
    "#6# id of div is footer. finding id name and adding to list. \n",
    "result = []\n",
    "for tag in soup.findAll(True,{'id':True}) :\n",
    "    result.append(tag['id'])\n",
    "\n",
    "id_div.append(result[2])\n",
    "print(id_div)\n",
    "\n",
    "#6# find the tag: p and select the name of the tag and adding to list for df\n",
    "soup.find(\"p\").name\n",
    "tag_name.append(soup.find(\"p\").name)\n",
    "\n",
    "print(tag_name)\n",
    "\n",
    "#5# finding the value 'Este párrafo está en el footer' and adding to value\n",
    "content_p = soup.findAll(\"p\")\n",
    "for pos, elem in enumerate(content_p):\n",
    "    if pos == 2:\n",
    "        content_value = elem.contents\n",
    "        value.append(content_value[0])\n",
    "        \n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Página de prueba', 'Página de prueba', 'Página de prueba', 'Página de prueba', 'Página de prueba', 'Página de prueba']\n['main', nan, nan, nan, 'footer', 'footer']\n['p', 'a', 'a', 'a', 'div', 'p']\n['Este es el primer párrafo', 'https://pagina1.xyz/', 'https://pagina4.xyz/', 'https://pagina5.xyz/', 'links footer-links', 'Este párrafo está en el footer']\n"
    }
   ],
   "source": [
    "#printing final lists:\n",
    "\n",
    "print(title)\n",
    "print(id_div)\n",
    "print(tag_name)\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating dataframe \n",
    "df = pd.DataFrame({\"Title\": title, \"Id\": id_div, \"Tag\": tag_name, \"Value\": value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              Title      Id  Tag                           Value\n0  Página de prueba    main    p       Este es el primer párrafo\n1  Página de prueba     NaN    a            https://pagina1.xyz/\n2  Página de prueba     NaN    a            https://pagina4.xyz/\n3  Página de prueba     NaN    a            https://pagina5.xyz/\n4  Página de prueba  footer  div              links footer-links\n5  Página de prueba  footer    p  Este párrafo está en el footer",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Id</th>\n      <th>Tag</th>\n      <th>Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Página de prueba</td>\n      <td>main</td>\n      <td>p</td>\n      <td>Este es el primer párrafo</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Página de prueba</td>\n      <td>NaN</td>\n      <td>a</td>\n      <td>https://pagina1.xyz/</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Página de prueba</td>\n      <td>NaN</td>\n      <td>a</td>\n      <td>https://pagina4.xyz/</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Página de prueba</td>\n      <td>NaN</td>\n      <td>a</td>\n      <td>https://pagina5.xyz/</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Página de prueba</td>\n      <td>footer</td>\n      <td>div</td>\n      <td>links footer-links</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Página de prueba</td>\n      <td>footer</td>\n      <td>p</td>\n      <td>Este párrafo está en el footer</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 216
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. From Amazon\n",
    "Using beautiful soap and/or regex\n",
    "\n",
    "Save in a dataframe the next information using web scraping. Using product pages from Amazon, do the following:\n",
    "\n",
    "Get the product name from the web and save it in a column called \"item_name\"\n",
    "Get the price from the web and save it in a column called \"item_price\"\n",
    "While you are doing the exercise, document the steps you are doing. Try to do the program for generic pages. If you cannot do it generic, explain the reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:\n",
    "\n",
    "url = https://www.amazon.es/Tommy-Hilfiger-UM0UM00054-Camiseta-Hombre/dp/B01MYD0T1F/ref=sr_1_1?dchild=1&pf_rd_p=58224bec-cac9-4dd2-a42a-61b1db609c2d&pf_rd_r=VZQ1JTQXFVRZ9E9VSKX4&qid=1595364419&s=apparel&sr=1-1\n",
    "\n",
    "item_name --> \"Tommy Hilfiger Logo Camiseta de Cuello Redondo,Perfecta para El Tiempo Libre para Hombre\"\n",
    "\n",
    "item_price --> [18,99 € - 46,59 €] or one of the options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "\n",
    "url = \"https://www.amazon.es/Tommy-Hilfiger-UM0UM00054-Camiseta-Hombre/dp/B01MYD0T1F/ref=sr_1_1?dchild=1&pf_rd_p=58224bec-cac9-4dd2-a42a-61b1db609c2d&pf_rd_r=VZQ1JTQXFVRZ9E9VSKX4&qid=1595364419&s=apparel&sr=1-1\"\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "#print(response.text)\n",
    "soup1 = BeautifulSoup(response.content, features=\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "item_name = []\n",
    "item_price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Tommy Hilfiger Logo Camiseta de Cuello Redondo,Perfecta para El Tiempo Libre para Hombre']\n"
    }
   ],
   "source": [
    "#Finding title from product and adding to item_name list.\n",
    "title = soup1.select(\"#productTitle\")[0].get_text().strip()\n",
    "item_name.append(title)\n",
    "print(item_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['18,99 € - 46,53 €']\n"
    }
   ],
   "source": [
    "#Finding price from product and adding to item_price list.\n",
    "price = soup1.select(\"#priceblock_ourprice\")[0].get_text()\n",
    "new_price = price.replace(u'\\xa0', u' ')\n",
    "item_price.append(new_price)\n",
    "print(item_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframe with lists.\n",
    "df_amazon = pd.DataFrame({\"item_name\": item_name, \"item_price\": item_price})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                           item_name         item_price\n0  Tommy Hilfiger Logo Camiseta de Cuello Redondo...  18,99 € - 46,53 €",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>item_name</th>\n      <th>item_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Tommy Hilfiger Logo Camiseta de Cuello Redondo...</td>\n      <td>18,99 € - 46,53 €</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 222
    }
   ],
   "source": [
    "df_amazon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#testing with another product/link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = \"https://www.amazon.es/dp/B07ZF8SB48/ref=sspa_dk_detail_0?psc=1&pd_rd_i=B07ZF8SB48&pd_rd_w=VTmt7&pf_rd_p=af12bbbd-c74b-4d8c-ad16-2ed2a7b363ab&pd_rd_wg=VqQFv&pf_rd_r=CDAT0AV7BBV8K9AMAEXJ&pd_rd_r=1dac10ed-d8e6-4e37-b561-f23cc7e31e7c&spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUExRFJQRTE3SVVZSDFEJmVuY3J5cHRlZElkPUEwODk5NjU5MlAwQ1I4OFNBWUQ4NCZlbmNyeXB0ZWRBZElkPUEwMTAzMzU0UVBXVEhOTUIzWENDJndpZGdldE5hbWU9c3BfZGV0YWlsJmFjdGlvbj1jbGlja1JlZGlyZWN0JmRvTm90TG9nQ2xpY2s9dHJ1ZQ==\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url2, headers=headers)\n",
    "#print(response.text)\n",
    "soup2 = BeautifulSoup(response.content, features=\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Tommy Hilfiger Logo Camiseta de Cuello Redondo,Perfecta para El Tiempo Libre para Hombre', 'LAPASA Pack de 2 Camisetas Hombre de Algodón ELS Manga Corta Camiseta Interior M05/M06']\n"
    }
   ],
   "source": [
    "#Finding title from product and adding to item_name list.\n",
    "title = soup2.select(\"#productTitle\")[0].get_text().strip()\n",
    "item_name.append(title)\n",
    "print(item_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['18,99 € - 46,53 €', '24,25 €']\n"
    }
   ],
   "source": [
    "#Finding price from product and adding to item_price list.\n",
    "price = soup2.select(\"#priceblock_ourprice\")[0].get_text()\n",
    "new_price = price.replace(u'\\xa0', u' ')\n",
    "item_price.append(new_price)\n",
    "print(item_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                           item_name         item_price\n0  Tommy Hilfiger Logo Camiseta de Cuello Redondo...  18,99 € - 46,53 €\n1  LAPASA Pack de 2 Camisetas Hombre de Algodón E...            24,25 €",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>item_name</th>\n      <th>item_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Tommy Hilfiger Logo Camiseta de Cuello Redondo...</td>\n      <td>18,99 € - 46,53 €</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LAPASA Pack de 2 Camisetas Hombre de Algodón E...</td>\n      <td>24,25 €</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 229
    }
   ],
   "source": [
    "df_amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---"
   ]
  }
 ]
}